{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distributed-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from itertools import permutations, combinations\n",
    "\n",
    "from numpy.random import default_rng\n",
    "from numpy.linalg import norm\n",
    "from scipy.special import softmax\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans, kmeans_plusplus\n",
    "import faiss\n",
    "import torch\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - x.mean(axis=0))/x.std(axis=0)\n",
    "\n",
    "def get_features(path, labels=None, norm=True):\n",
    "    data = np.load(path)\n",
    "    if labels:\n",
    "        s = data[labels]\n",
    "        sx, sy = s[:, :-1], s[:, -1]\n",
    "        return sx, sy\n",
    "    ss, st = data['s'], data['t']\n",
    "    ssx, ssy = ss[:, :-1], ss[:, -1]\n",
    "    stx, sty = st[:, :-1], st[:, -1]\n",
    "    if norm:\n",
    "        return normalize(ssx), ssy, normalize(stx), sty\n",
    "    return ssx, ssy, stx, sty\n",
    "\n",
    "def prototype_classifier(X, C, th=1):\n",
    "    dist = cdist(C, X)\n",
    "    prob = softmax(-dist, axis=0)\n",
    "#     prob = softmax(1/(1+dist), axis=0)\n",
    "    return prob.argsort(axis=0)[-th:][::-1, :], prob\n",
    "\n",
    "# def prototype_classifier(X, C):\n",
    "#     dist = cdist(C, X)\n",
    "#     prob = softmax(-dist, axis=0)\n",
    "#     return prob.T\n",
    "\n",
    "def masked_prototypical_classifier(X, C, ratio=0.3, seed=2437, th=2):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    masked_idx = ~rng.binomial(1, ratio, X.shape[1]).astype(bool)\n",
    "    return prototype_classifier(X[:, masked_idx], C[:, masked_idx], th=th)\n",
    "\n",
    "def labeled_data_sampler(labels, shot=1, seed=1362):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    size = len(np.unique(labels))\n",
    "    idx = np.stack([rng.choice(np.where(labels == i)[0], shot) for i in range(size)]).flatten().astype(int)\n",
    "    return idx, np.setdiff1d(np.arange(len(labels)), idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "intelligent-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(4):\n",
    "    s_path = f'./OfficeHome/source_only/s{s}_t{(s+1)%4}.npz'\n",
    "    ssx, ssy, stx, sty = get_features(s_path, norm=False)\n",
    "\n",
    "    ssc = np.stack([ssx[ssy == i].mean(axis=0) for i in range(65)])\n",
    "    with open(f's{s}_center.npy', 'wb') as f:\n",
    "        np.save(f, ssc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consecutive-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "\n",
    "path = f'./OfficeHome/source_only/s0_t1_2020.npz'\n",
    "sx, sy, tx, ty = get_features(path, norm=False)\n",
    "\n",
    "l_idx, u_idx = labeled_data_sampler(ty, shot=3, seed=seed)\n",
    "ltx, lty, utx, uty = tx[l_idx], ty[l_idx], tx[u_idx], ty[u_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "serious-stock",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== source 0, target 1 ==========\n",
      "0.5571592210767469\n",
      "========== source 0, target 2 ==========\n",
      "0.7449876098220319\n",
      "========== source 0, target 3 ==========\n",
      "0.7805829699334405\n",
      "========== source 1, target 0 ==========\n",
      "0.6662546353522868\n",
      "========== source 1, target 2 ==========\n",
      "0.7186303221446272\n",
      "========== source 1, target 3 ==========\n",
      "0.7296304796878587\n",
      "========== source 2, target 0 ==========\n",
      "0.6398846312319736\n",
      "========== source 2, target 1 ==========\n",
      "0.5475372279495991\n",
      "========== source 2, target 3 ==========\n",
      "0.7895340830846913\n",
      "========== source 3, target 0 ==========\n",
      "0.7161104243922538\n",
      "========== source 3, target 1 ==========\n",
      "0.5802978235967927\n",
      "========== source 3, target 2 ==========\n",
      "0.813922054516783\n",
      "Avg. score: 0.690377623565757\n"
     ]
    }
   ],
   "source": [
    "avg = 0\n",
    "for s, t in permutations(range(4), 2):\n",
    "    s_path = f'./OfficeHome/s2t_shot/s{s}_t{t}_{2024+s}.npz'\n",
    "    ssx, ssy, stx, sty = get_features(s_path, norm=False)\n",
    "\n",
    "    ssc = np.stack([ssx[ssy == i].mean(axis=0) for i in range(65)])\n",
    "    stc = np.stack([stx[sty == i].mean(axis=0) for i in range(65)])\n",
    "\n",
    "    pred, _ = prototype_classifier(stx, ssc)\n",
    "    pred = pred.flatten()\n",
    "\n",
    "#     if np.unique(pred).__len__() == 65:\n",
    "#         pseudo_c = np.stack([stx[pred == i].mean(axis=0) for i in range(65)])\n",
    "#         pred, _ = prototype_classifier(stx, pseudo_c)\n",
    "    \n",
    "    print('='*10, f'source {s}, target {t}', '='*10)\n",
    "    score = (pred == sty).mean()\n",
    "    avg += score\n",
    "    print(score)\n",
    "print('Avg. score:', avg / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-compression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "damaged-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_path = f'./OfficeHome/kmeans_source_only/s{0}_t{1}_2.npz'\n",
    "s_path = f'./OfficeHome/s2t_shot/s{0}_t{1}.npz'\n",
    "\n",
    "# ssx, ssy, stx, _ = get_features(t_path, norm=False)\n",
    "# _, _, _, sty = get_features(s_path, norm=False)\n",
    "ssx, ssy, stx, sty = get_features(s_path, norm=False)\n",
    "ssc = np.stack([ssx[ssy == i].mean(axis=0) for i in range(65)])\n",
    "# stc = np.stack([stx[sty == i].mean(axis=0) for i in range(65)])\n",
    "\n",
    "# label_map, _ = prototype_classifier(stc, ssc)\n",
    "# label_map = label_map.flatten()\n",
    "# pred = label_map[sty.astype(int)]\n",
    "# print(pred)\n",
    "# print((pred == correct_sty).mean())\n",
    "stx = stx.astype('float32')\n",
    "ssx = ssx.astype('float32')\n",
    "n_clusters = 65\n",
    "# print(n_clusters)\n",
    "\n",
    "seed = 1347\n",
    "# pseudo_c = np.stack([stx[pred.flatten() == i].mean(axis=0) for i in range(65)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "collected-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers, _ = kmeans_plusplus(stx, n_clusters=n_clusters, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "random-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = faiss.Kmeans(stx.shape[1], n_clusters, niter=300, nredo=5, gpu=True, seed=seed)\n",
    "kmeans.train(stx, init_centroids=ssc.astype('float32'))\n",
    "t_pred = kmeans.index.search(stx, 1)[1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "generous-recipe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 256)\n"
     ]
    }
   ],
   "source": [
    "centroids = kmeans.centroids\n",
    "print(centroids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "polar-relevance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 34 13 14 46 16 33 18 19 20 21 22 38\n",
      " 24 25 26 27 28 29 30 31 32 23 34 35 36 37 38 39 40 41 42 43 60 45 46 47\n",
      " 48 49 50 51 52 26 54 55 56 57 58 59 60 61 62 63 64]\n"
     ]
    }
   ],
   "source": [
    "centroids_y = np.array([int(mode(sty[np.where(t_pred==i)[0]]).mode.item()) for i in range(n_clusters)])\n",
    "print(centroids_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "considered-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = prototype_classifier(centroids, ssc)\n",
    "pred = pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "serial-reaction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 59 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 18 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 23 54 55 56 57 58 59 60 61 62 63 56]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "extreme-optics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076923076923077\n"
     ]
    }
   ],
   "source": [
    "print((pred == centroids_y).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "increased-campaign",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4888372093023256\n"
     ]
    }
   ],
   "source": [
    "centroids_map = pred.copy()\n",
    "c_pred, _ = prototype_classifier(stx, centroids)\n",
    "c_pred = c_pred.flatten()\n",
    "new_pred = centroids_map[c_pred]\n",
    "\n",
    "print((new_pred == sty).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dried-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pred = kmeans.index.search(ssc.astype('float32'), 1)[1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "straight-willow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 63, 11, 56, 49,  2,  6, 13, 47, 64, 30, 24,  3, 48, 59, 51, 14,\n",
       "       45, 18, 50, 15, 57, 31, 54, 61, 55, 14, 63, 32, 42, 34, 20, 10, 45,\n",
       "       62, 61, 40, 27, 24, 44, 33, 38, 26, 45, 54, 43, 23, 16, 37, 17, 39,\n",
       "        4, 46, 46,  0, 11, 22, 61, 19, 51, 29, 61, 41,  6, 21])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aerial-equivalent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5576744186046512\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    idx = np.where(t_pred==i)[0]\n",
    "    n = sty[idx]\n",
    "    cnt += mode(n)[1][0]\n",
    "print(cnt/len(stx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
